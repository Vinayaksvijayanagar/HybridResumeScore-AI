{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume_inference_superclean.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import joblib\n",
    "import docx\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PATHS\n",
    "# ------------------------------------------------------------------\n",
    "ARTIFACTS_PATH = \"/content/drive/MyDrive/Resume_Score/resume_pipeline_output/resume_pipeline_artifacts.joblib\"\n",
    "RESUME_FOLDER = \"/content/drive/MyDrive/Resume_Score/resumes/\"\n",
    "OUTPUT_SENTENCE_CSV = \"/content/drive/MyDrive/Resume_Score/superclean_sentence_predictions.csv\"\n",
    "OUTPUT_RESUME_SCORES = \"/content/drive/MyDrive/Resume_Score/superclean_resume_scores.csv\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# LOAD MODEL\n",
    "# ------------------------------------------------------------------\n",
    "artifacts = joblib.load(ARTIFACTS_PATH)\n",
    "tfidf = artifacts[\"tfidf\"]\n",
    "clf = artifacts[\"logistic_clf\"]\n",
    "categories = list(artifacts[\"categories\"])\n",
    "action_verbs = artifacts[\"action_verbs\"]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# TEXT EXTRACTION\n",
    "# ------------------------------------------------------------------\n",
    "def extract_text(path):\n",
    "    if path.endswith(\".txt\"):\n",
    "        return open(path, \"r\", errors=\"ignore\").read()\n",
    "\n",
    "    if path.endswith(\".docx\"):\n",
    "        doc = docx.Document(path)\n",
    "        return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "    if path.endswith(\".pdf\"):\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                t = page.extract_text()\n",
    "                if t:\n",
    "                    text += t + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# SENTENCE SPLIT\n",
    "# ------------------------------------------------------------------\n",
    "def extract_sentences(text):\n",
    "    text = text.replace(\"\\n\", \". \")\n",
    "    parts = re.split(r\"[.!?]\", text)\n",
    "    return [p.strip() for p in parts if len(p.strip()) > 8]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PERSONAL DETAILS & NON-TECH DETECTION\n",
    "# ------------------------------------------------------------------\n",
    "PERSONAL_KEYWORDS = [\n",
    "    \"name\", \"phone\", \"email\", \"gmail\", \"linkedin\", \"dob\", \"date of birth\",\n",
    "    \"address\", \"age\", \"contact\", \"father\", \"mother\", \"nationality\", \"pincode\"\n",
    "]\n",
    "\n",
    "EDUCATION_KEYWORDS = [\n",
    "    \"bachelor\", \"master\", \"degree\", \"university\", \"college\",\n",
    "    \"percentage\", \"cgpa\", \"puc\", \"sslc\", \"class x\", \"class 12\",\n",
    "    \"puc ii\", \"semester\", \"graduation\"\n",
    "]\n",
    "\n",
    "\n",
    "def is_personal_or_education(sentence):\n",
    "    s = sentence.lower()\n",
    "    return any(k in s for k in PERSONAL_KEYWORDS + EDUCATION_KEYWORDS)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# CATEGORY KEYWORD FILTERS (hard rules)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "ML_KEYWORDS = [\n",
    "    \"machine learning\", \"ml\", \"model\", \"training\", \"regression\", \"classification\",\n",
    "    \"prediction\", \"algorithm\", \"deep learning\", \"neural network\", \"xgboost\",\n",
    "    \"random forest\", \"svm\", \"pipeline\", \"accuracy\", \"f1\", \"precision\", \"recall\"\n",
    "]\n",
    "\n",
    "NLP_KEYWORDS = [\n",
    "    \"nlp\", \"text\", \"bert\", \"gpt\", \"token\", \"embedding\", \"sentiment\",\n",
    "    \"ner\", \"transformer\", \"language model\", \"translation\", \"summarization\"\n",
    "]\n",
    "\n",
    "CV_KEYWORDS = [\n",
    "    \"image\", \"vision\", \"opencv\", \"cnn\", \"camera\", \"pixels\", \"yolo\",\n",
    "    \"face detection\", \"object detection\", \"segmentation\", \"frames\"\n",
    "]\n",
    "\n",
    "\n",
    "def contains_any(sentence, keywords):\n",
    "    s = sentence.lower()\n",
    "    return any(k in s for k in keywords)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# HYBRID PREDICT WITH ALL FILTERS (THE FIX)\n",
    "# ------------------------------------------------------------------\n",
    "def hybrid_predict(sentence):\n",
    "    # PERSONAL/EDUCATION â†’ ALWAYS OTHER\n",
    "    if is_personal_or_education(sentence):\n",
    "        return \"OTHER\"\n",
    "\n",
    "    # CLASSIFIER\n",
    "    X_tfidf = tfidf.transform([sentence])\n",
    "    act = 1 if action_verbs.intersection(sentence.lower().split()) else 0\n",
    "    X_final = hstack([X_tfidf, [[act]]])\n",
    "\n",
    "    probs = clf.predict_proba(X_final)[0]\n",
    "    pred = clf.predict(X_final)[0]\n",
    "    confidence = max(probs)\n",
    "\n",
    "    # RULE 1: Confidence threshold\n",
    "    if confidence < 0.1:\n",
    "        return \"OTHER\"\n",
    "\n",
    "    # RULE 2: ML keyword validation\n",
    "    if pred == \"ML / Modeling\" and not contains_any(sentence, ML_KEYWORDS):\n",
    "        return \"OTHER\"\n",
    "\n",
    "    # RULE 3: NLP keyword validation\n",
    "    if pred == \"NLP\" and not contains_any(sentence, NLP_KEYWORDS):\n",
    "        return \"OTHER\"\n",
    "\n",
    "    # RULE 4: Computer Vision keyword validation\n",
    "    if pred == \"Computer Vision\" and not contains_any(sentence, CV_KEYWORDS):\n",
    "        return \"OTHER\"\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PYTHON SKILL SCORE\n",
    "# ------------------------------------------------------------------\n",
    "PYTHON_KEYS = [\n",
    "    \"python\", \"numpy\", \"pandas\", \"sklearn\", \"tensorflow\", \"pytorch\",\n",
    "    \"keras\", \"flask\", \"fastapi\", \"django\", \"matplotlib\", \"jupyter\"\n",
    "]\n",
    "\n",
    "\n",
    "def python_score(sentences):\n",
    "    hits = sum(1 for s in sentences if any(k in s.lower() for k in PYTHON_KEYS))\n",
    "    return (hits / len(sentences)) * 100 if sentences else 0\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# PROCESS RESUMES\n",
    "# ------------------------------------------------------------------\n",
    "sentence_rows = []\n",
    "resume_rows = []\n",
    "\n",
    "for file in os.listdir(RESUME_FOLDER):\n",
    "    if not file.lower().endswith((\".pdf\", \".docx\", \".txt\")):\n",
    "        continue\n",
    "\n",
    "    print(\"Processing:\", file)\n",
    "    path = os.path.join(RESUME_FOLDER, file)\n",
    "    text = extract_text(path)\n",
    "    sentences = extract_sentences(text)\n",
    "\n",
    "    preds = [hybrid_predict(s) for s in sentences]\n",
    "\n",
    "    # SAVE PER-SENTENCE OUTPUT\n",
    "    for s, p in zip(sentences, preds):\n",
    "        sentence_rows.append([file, s, p])\n",
    "\n",
    "    # SCORE RESUME\n",
    "    total = len(preds)\n",
    "    ml = preds.count(\"ML / Modeling\") / total * 100 if total else 0\n",
    "    nlp = preds.count(\"NLP\") / total * 100 if total else 0\n",
    "    py = python_score(sentences)\n",
    "\n",
    "    # Experience calculation\n",
    "    yrs = 0\n",
    "    found = re.findall(r\"(\\d+)\\s*(years|year|yrs)\", text.lower())\n",
    "    if found:\n",
    "        yrs = max(int(x[0]) for x in found)\n",
    "    exp = 100 if yrs >= 5 else (yrs / 5 * 100)\n",
    "\n",
    "    overall = (ml + nlp + py + exp) / 4\n",
    "\n",
    "    resume_rows.append([\n",
    "        file, round(ml, 2), round(nlp, 2),\n",
    "        round(py, 2), yrs, round(exp, 2),\n",
    "        round(overall, 2)\n",
    "    ])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# SAVE OUTPUT\n",
    "# ------------------------------------------------------------------\n",
    "pd.DataFrame(sentence_rows, columns=[\"Resume\", \"Sentence\", \"Category\"]).to_csv(\n",
    "    OUTPUT_SENTENCE_CSV, index=False\n",
    ")\n",
    "\n",
    "pd.DataFrame(resume_rows, columns=[\n",
    "    \"Resume\", \"AI/ML Match (%)\", \"NLP Match (%)\", \"Python Match (%)\",\n",
    "    \"Years Experience\", \"Experience Score (%)\", \"Overall Score (%)\"\n",
    "]).to_csv(OUTPUT_RESUME_SCORES, index=False)\n",
    "\n",
    "print(\"\\nSUPER CLEAN INFERENCE DONE.\")\n",
    "print(\"Saved:\", OUTPUT_SENTENCE_CSV)\n",
    "print(\"Saved:\", OUTPUT_RESUME_SCORES)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
